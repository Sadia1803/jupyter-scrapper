from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
from openpyxl import load_workbook
import os
from urllib.parse import urljoin

# Set up Chrome options
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument("--headless")
chrome_options.add_argument("--window-size=1920,1080")
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration

def scrape_mobiles_and_installments(url):
    # Set up the Selenium WebDriver
    driver = webdriver.Chrome(options=chrome_options)
    driver.get(url)

    all_mobiles = []

    try:
        # Wait for the initial content to load
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CLASS_NAME, "ps-product__title"))
        )

        # Extract initial data
        initial_html = driver.page_source
        initial_soup = BeautifulSoup(initial_html, "html.parser")
        initial_products = initial_soup.find_all("div", class_="ps-product")

        for product in initial_products:
            mobile_data = extract_mobile_data(driver, product, url)
            if mobile_data:
                all_mobiles.append(mobile_data)

        # Simulate scroll events to load additional content
        for scroll_count in range(4):  # Adjust the number of scroll events as needed
            # Scroll down using JavaScript
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

            # Wait for the dynamically loaded content to appear
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "ps-product__title"))
            )

            # Extract the newly loaded products
            scroll_html = driver.page_source
            scroll_soup = BeautifulSoup(scroll_html, "html.parser")
            scroll_products = scroll_soup.find_all("div", class_="ps-product")

            for product in scroll_products:
                mobile_data = extract_mobile_data(driver, product, url)
                if mobile_data:
                    all_mobiles.append(mobile_data)

    except Exception as e:
        print(f"Error occurred while loading the page: {e}")

    finally:
        # Close the WebDriver
        driver.quit()

    # Save the data to an Excel file
    save_to_excel(all_mobiles)

def extract_mobile_data(driver, product, base_url):
    try:
        name_tag = product.find("a", class_="ps-product__title")
        price_tag = product.find("p", class_="ps-product__display-amount")

        if name_tag and price_tag:
            name = name_tag.get_text(strip=True)
            price = price_tag.get_text(strip=True).replace('Rs.', '').strip()
            product_link = name_tag['href']
            product_url = urljoin(base_url, product_link)

            driver.get(product_url)

            WebDriverWait(driver, 20).until(
                EC.presence_of_element_located((By.CLASS_NAME, "installment-plan"))
            )

            details_html = driver.page_source
            details_soup = BeautifulSoup(details_html, "html.parser")

            # Extract installment plans
            installment_plans = extract_installment_plans(details_soup)

            return {'Model': name, 'Price': price, 'Installment Plans': installment_plans}
        return None

    except Exception as e:
        print(f"Error loading product details for {name}: {e}")
        return None

def extract_installment_plans(details_soup):
    plans = []
    installment_plan_divs = details_soup.find_all("div", class_="installment-plan")

    for plan_div in installment_plan_divs:
        label = plan_div.find("label")
        if label:
            plan_text = label.get_text(separator=" ", strip=True)
            plans.append(plan_text)

    return plans

def save_to_excel(data):
    df = pd.DataFrame(data)
    
    # Get current date
    current_date = datetime.now().strftime('%Y-%m-%d')
    
    # Define the file name
    file_name = 'mobiles_installments.xlsx'
    
    # Define the sheet name with the current date
    sheet_name = f'qistbazaar_mobiles_{current_date}'
    
    # Save the DataFrame to an Excel file with the specified sheet name
    if os.path.exists(file_name):
        with pd.ExcelWriter(file_name, engine='openpyxl', mode='a') as writer:
            if sheet_name in writer.book.sheetnames:
                sheet_name = f"{sheet_name}_new"
            df.to_excel(writer, index=False, sheet_name=sheet_name)
    else:
        with pd.ExcelWriter(file_name, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name=sheet_name)
    
    print(f"Data has been saved to sheet '{sheet_name}' in {file_name} on {current_date}")

if __name__ == "__main__":
    target_url = "https://www.qistbazaar.pk/product-category/mobiles"
    scrape_mobiles_and_installments(target_url)
